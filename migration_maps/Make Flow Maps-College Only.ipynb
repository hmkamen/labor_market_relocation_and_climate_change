{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f40966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d679d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp0_gr=tmp0.groupby(['msa','statefip'],as_index=False).agg({'id':sum})\n",
    "# bmk0_gr=bmk0.groupby(['msa'],as_index=False).agg({'id':sum})\n",
    "# msaid_state_lookup=tmp0_gr[['msa','statefip']].merge(bmk0_gr[['msa']],on='msa').groupby(['msa','statefip'],as_index=False).sum()\n",
    "# msaid_state_lookup.to_excel('/Users/hannahkamen/Downloads/msaid_state_lookup.xlsx')\n",
    "\n",
    "#####get MSA Identifier information\n",
    "# msa_id=pd.read_stata('/Users/hannahkamen/Downloads/population-migration-master/estimation/1_main_specification/acs5yr0610/dta/msa_identifier.dta')\n",
    "# msa_vars=pd.read_stata('/Users/hannahkamen/Downloads/population-migration-master/estimation/1_main_specification/acs5yr0610/dta/second_stage_dataset_cl.dta')\n",
    "state_split=pd.read_excel('/Users/hannahkamen/Downloads/state_pop_educ_shares.xlsx')\n",
    "sl=pd.read_excel('/Users/hannahkamen/Downloads/statelookup2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e469be9",
   "metadata": {},
   "source": [
    "##### (2) get coordinate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7e17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###prepare dataset with centroid of every state\n",
    "\n",
    "map_dta1=pd.read_csv('/Users/hannahkamen/Downloads/census_texas.csv')\n",
    "map_dta2=pd.read_csv('/Users/hannahkamen/Downloads/census_ny.csv')\n",
    "map_dta=map_dta1.append(map_dta2).reset_index()\n",
    "\n",
    "###rename data\n",
    "map_dta['centroid2']=map_dta['centroid1']+\",\"+map_dta['centroid2']\n",
    "map_dta['centroid1']=map_dta['FULL1_NAME']+\",\"+map_dta['FULL2_NAME']\n",
    "map_dta['FULL1_NAME']=map_dta['GEOID1']\n",
    "map_dta['FULL2_NAME']=map_dta['GEOID2']\n",
    "\n",
    "del map_dta['GEOID1']\n",
    "del map_dta['GEOID2']\n",
    "\n",
    "\n",
    "map_dta['GEOID1']=map_dta['level_1']\n",
    "map_dta['GEOID2']=map_dta['Unnamed: 0']\n",
    "map_dta=map_dta[['GEOID1','GEOID2','FULL1_NAME','FULL2_NAME','centroid1','centroid2']]\n",
    "####get abbreviations\n",
    "\n",
    "states=list(sl['abbrev'].unique())\n",
    "\n",
    "state_coords=pd.DataFrame()\n",
    "for s in states:\n",
    "    tmp=map_dta[map_dta['FULL2_NAME'].str.contains(s)]\n",
    "    tmp['state']=s\n",
    "    state_coords=state_coords.append(tmp)\n",
    "state_coords=state_coords.drop_duplicates(subset='state')\n",
    "state_coords=state_coords[['state','FULL2_NAME','centroid2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8877bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_coords['id']= np.arange(len(state_coords))\n",
    "state_coords['name']=state_coords['state']\n",
    "state_coords['lat']=state_coords['centroid2'].apply(lambda x: x.split(',')[1].replace(\")\",'').strip())\n",
    "state_coords['lon']=state_coords['centroid2'].apply(lambda x: x.split(',')[0].replace(\"(\",'').replace(\"c\",'').strip())\n",
    "state_coords_lm=state_coords[['id','name','lat','lon']]\n",
    "state_coords_lm.to_csv('/Users/hannahkamen/Downloads/flowmap_location_lookup.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372b6c7",
   "metadata": {},
   "source": [
    "##### (2) map out migration flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78122c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####import state pop shares by skilled and unskilled\n",
    "state_educ=pd.read_excel('/Users/hannahkamen/Downloads/state_educ_shares.xlsx')\n",
    "del state_educ['statefip']\n",
    "state_educ=state_educ.merge(sl,on='state',how='inner')\n",
    "state_educ=state_educ[['statefip','skl','unskl','state','abbrev','state_pop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02376ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###these are the population shares changes from the first cycle of GAMS data inputs (after initial logit shock with temp)\n",
    "###the shares caluclated here represent the population change from the previous iteration \n",
    "state_split=pd.read_excel('/Users/hannahkamen/Downloads/state_pop_educ_shares.xlsx')\n",
    "\n",
    "msaid_state_lookup=pd.read_excel('/Users/hannahkamen/Downloads/msaid_state_lookup.xlsx')\n",
    "sl=pd.read_excel('/Users/hannahkamen/Downloads/statelookup2.xlsx')\n",
    "tmp0=pd.read_stata('/Users/hannahkamen/Downloads/population-migration-master/estimation/1_main_specification/acs5yr0610/dta/projection_data_age2_01_wbmk_v2_0_college_only.dta')\n",
    "tmp0=tmp0.merge(sl,on='statefip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013e4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####store in csv\n",
    "\n",
    "master_map_unskl2=tmp0[tmp0['coll']==0]\n",
    "master_map_skl2=tmp0[tmp0['coll']==1]\n",
    "\n",
    "master_map_unskl2.to_csv('/Users/hannahkamen/Downloads/map_data_unskl2_college_only.csv')\n",
    "master_map_skl2.to_csv('/Users/hannahkamen/Downloads/map_data_skl2_college_only.csv')\n",
    "\n",
    "del tmp0\n",
    "del master_map_unskl2\n",
    "del master_map_skl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e3f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_map_unskl2=pd.read_csv('/Users/hannahkamen/Downloads/map_data_unskl2_college_only.csv')\n",
    "master_map_skl2=pd.read_csv('/Users/hannahkamen/Downloads/map_data_skl2_college_only.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2912f4",
   "metadata": {},
   "source": [
    "#### Unskilled Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74bf809",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### prep data for map\n",
    "\n",
    "#get sum of shares in all other states for people who chose states 1-44\n",
    "#get ids that live in state s currentlly\n",
    "unskl=pd.DataFrame()\n",
    "for s in master_map_unskl2['state'].unique():\n",
    "    living_now=[]\n",
    "    tmp1=master_map_unskl2[(master_map_unskl2['state']==s) & (master_map_unskl2['chosen']==1)]\n",
    "    ####list of ids currently living in state s\n",
    "    living_now.append(list(tmp1['id'].unique())[0])\n",
    "    ###limit dataframe to the ids of people living in state s\n",
    "    tmp2=master_map_unskl2[master_map_unskl2['id'].isin(living_now)]\n",
    "    ####now groupby shares across all states\n",
    "    tmp3=tmp2.groupby(['state'],as_index=False).agg({'share0':sum,'shareb':sum})\n",
    "    ###tag origin state\n",
    "    tmp3['living_flag']=s\n",
    "    unskl=unskl.append(tmp3)\n",
    "    \n",
    "######merge with state populaiton\n",
    "unskl=unskl.merge(state_split,left_on='living_flag',right_on='state',how='inner')\n",
    "unskl=unskl.rename(columns={'state_x':'moving_to'})\n",
    "\n",
    "######get share difference between current  iteration and benchmark\n",
    "unskl['share_diff']=unskl['share0']-unskl['shareb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec84095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_map_skl2[master_map_skl2['chosen']==1]['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c7f89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_map_unskl2[master_map_unskl2['chosen']==1]['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c16fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### prep data for map\n",
    "\n",
    "#get sum of shares in all other states for people who chose states 1-44\n",
    "#get ids that live in state s currentlly\n",
    "skl=pd.DataFrame()\n",
    "for s in master_map_skl2['state'].unique():\n",
    "    living_now=[]\n",
    "    tmp1=master_map_skl2[(master_map_skl2['state']==s) & (master_map_skl2['chosen']==1)]\n",
    "    ####list of ids currently living in state s\n",
    "    living_now.append(list(tmp1['id'].unique())[0])\n",
    "    ###limit dataframe to the ids of people living in state s\n",
    "    tmp2=master_map_skl2[master_map_skl2['id'].isin(living_now)]\n",
    "    ####now groupby shares across all states\n",
    "    tmp3=tmp2.groupby(['state'],as_index=False).agg({'share0':sum,'shareb':sum})\n",
    "    ###tag origin state\n",
    "    tmp3['living_flag']=s\n",
    "    skl=skl.append(tmp3)\n",
    "    \n",
    "######merge with state populaiton\n",
    "skl=skl.merge(state_split,left_on='living_flag',right_on='state',how='inner')\n",
    "skl=skl.rename(columns={'state_x':'moving_to'})\n",
    "\n",
    "######get share difference between current  iteration and benchmark\n",
    "skl['share_diff']=skl['share0']-skl['shareb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb669b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "####read in pct changes by state and education\n",
    "le0=pd.read_csv('/Users/hannahkamen/Downloads/le0_shock0_v2_test2_college_only.csv')\n",
    "\n",
    "le0=le0[['r','sk','skill_shr']]\n",
    "le0=le0.drop_duplicates(subset=['r','sk'])\n",
    "le0=le0.rename(columns={'sk':'educ_id','skill_shr':'final_change','r':'abbrev'})\n",
    "le0=le0.merge(sl,on='abbrev')\n",
    "le0_skl=le0[le0['educ_id']=='skl']\n",
    "le0_unskl=le0[le0['educ_id']=='unskl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c59f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####prepare pop map data for skilled entrance\n",
    "all_skl_entrance=pd.DataFrame()\n",
    "\n",
    "for s in le0_skl[le0_skl['final_change']>0]['state'].unique():\n",
    "    ###for each entrance state, calculate shares by origin state that make up total change in the positive share diff\n",
    "    master_map_skl_lm=skl[((skl['moving_to']==s) & (skl['share_diff']>0))]\n",
    "    #####get totals \n",
    "    master_map_skl_lm_totalinflows=master_map_skl_lm.groupby('moving_to').agg({'share_diff':sum})\n",
    "    ###rename and merge\n",
    "    master_map_skl_lm_totalinflows=master_map_skl_lm_totalinflows.rename(columns={'share_diff':'share_diff_tot'})\n",
    "    master_map_skl_lm=master_map_skl_lm.merge(master_map_skl_lm_totalinflows,on='moving_to')\n",
    "    \n",
    "    master_map_skl_lm['inflow_share']= master_map_skl_lm['share_diff']/master_map_skl_lm['share_diff_tot']\n",
    "    \n",
    "    master_map_skl_lm=master_map_skl_lm[['moving_to','living_flag','inflow_share','share_diff_tot']]\n",
    "    all_skl_entrance=all_skl_entrance.append(master_map_skl_lm)\n",
    "    \n",
    "all_skl_entrance=all_skl_entrance.merge(state_educ,left_on='moving_to',right_on='state').merge(le0_skl,on='state')\n",
    "all_skl_entrance['raw_pop_change_moving_to']=all_skl_entrance['final_change']*all_skl_entrance['state_pop']*all_skl_entrance['skl']*all_skl_entrance['inflow_share']\n",
    "\n",
    "##merge in pop info\n",
    "\n",
    "all_skl_entrance=all_skl_entrance.rename(columns={'abbrev_x':'dest'})\n",
    "all_skl_entrance=all_skl_entrance.merge(sl[['state','abbrev']],left_on='living_flag',right_on='state')\n",
    "all_skl_entrance=all_skl_entrance.rename(columns={'abbrev':'origin'})\n",
    "\n",
    "all_skl_entrance=all_skl_entrance.merge(state_coords_lm,left_on='dest',right_on='name')\n",
    "del all_skl_entrance['dest']\n",
    "all_skl_entrance['dest']=all_skl_entrance['id']\n",
    "del all_skl_entrance['id']\n",
    "all_skl_entrance=all_skl_entrance.merge(state_coords_lm,left_on='origin',right_on='name')\n",
    "del all_skl_entrance['origin']\n",
    "\n",
    "\n",
    "# all_skl_entrance=all_skl_entrance.merge(state_educ,left_on='moving_to',right_on='state').merge(total_skilled_pop_changes,left_on='moving_to',right_on='statefip')\n",
    "all_skl_entrance['origin']=all_skl_entrance['id']\n",
    "all_skl_entrance['count']=all_skl_entrance['raw_pop_change_moving_to']\n",
    "\n",
    "all_skl_entrance_lm=all_skl_entrance[['origin','dest','count']]\n",
    "all_skl_entrance_lm['count']=all_skl_entrance_lm['count']/14412444.2\n",
    "all_skl_entrance_lm.to_csv('/Users/hannahkamen/Downloads/skilled_entrance_college_only.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2379241f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'moving_to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w1/12ls607j77q1jk587t2n5t2r0000gn/T/ipykernel_81950/2947023246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_map_unskl_lm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_educ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'moving_to'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle0_unskl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_pop_change_moving_to'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_pop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unskl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_unskl_entrance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inflow_share'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9188\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9190\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   9191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9192\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 106\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'moving_to'"
     ]
    }
   ],
   "source": [
    "#####prepare pop map data for skilled entrance\n",
    "all_unskl_entrance=pd.DataFrame()\n",
    "\n",
    "for s in le0_unskl[le0_unskl['final_change']>0]['state'].unique():\n",
    "    ###for each entrance state, calculate shares by origin state that make up total change in the positive share diff\n",
    "    master_map_unskl_lm=unskl[((unskl['moving_to']==s) & (unskl['share_diff']>0))]\n",
    "    #####get totals \n",
    "    master_map_unskl_lm_totalinflows=master_map_unskl_lm.groupby('moving_to').agg({'share_diff':sum})\n",
    "    ###rename and merge\n",
    "    master_map_unskl_lm_totalinflows=master_map_unskl_lm_totalinflows.rename(columns={'share_diff':'share_diff_tot'})\n",
    "    master_map_unskl_lm=master_map_unskl_lm.merge(master_map_unskl_lm_totalinflows,on='moving_to')\n",
    "    \n",
    "    master_map_unskl_lm['inflow_share']= master_map_unskl_lm['share_diff']/master_map_unskl_lm['share_diff_tot']\n",
    "    \n",
    "    master_map_unskl_lm=master_map_unskl_lm[['moving_to','living_flag','inflow_share','share_diff_tot']]\n",
    "    all_unskl_entrance=all_unskl_entrance.append(master_map_unskl_lm)\n",
    "    \n",
    "all_unskl_entrance=all_unskl_entrance.merge(state_educ,left_on='moving_to',right_on='state').merge(le0_unskl,on='state')\n",
    "all_unskl_entrance['raw_pop_change_moving_to']=all_unskl_entrance['final_change']*all_unskl_entrance['state_pop']*all_unskl_entrance['unskl']*all_unskl_entrance['inflow_share']\n",
    "\n",
    "##merge in pop info\n",
    "\n",
    "all_unskl_entrance=all_unskl_entrance.rename(columns={'abbrev_x':'dest'})\n",
    "all_unskl_entrance=all_unskl_entrance.merge(sl[['state','abbrev']],left_on='living_flag',right_on='state')\n",
    "all_unskl_entrance=all_unskl_entrance.rename(columns={'abbrev':'origin'})\n",
    "\n",
    "all_unskl_entrance=all_unskl_entrance.merge(state_coords_lm,left_on='dest',right_on='name')\n",
    "del all_unskl_entrance['dest']\n",
    "all_unskl_entrance['dest']=all_unskl_entrance['id']\n",
    "del all_unskl_entrance['id']\n",
    "all_unskl_entrance=all_unskl_entrance.merge(state_coords_lm,left_on='origin',right_on='name')\n",
    "del all_unskl_entrance['origin']\n",
    "\n",
    "\n",
    "# all_unskl_entrance=all_unskl_entrance.merge(state_educ,left_on='moving_to',right_on='state').merge(total_skilled_pop_changes,left_on='moving_to',right_on='statefip')\n",
    "all_unskl_entrance['origin']=all_unskl_entrance['id']\n",
    "all_unskl_entrance['count']=all_unskl_entrance['raw_pop_change_moving_to']\n",
    "\n",
    "all_unskl_entrance_lm=all_unskl_entrance[['origin','dest','count']]\n",
    "\n",
    "all_unskl_entrance_lm['count']=all_unskl_entrance_lm['count']/14412444.2\n",
    "\n",
    "all_unskl_entrance_lm.to_csv('/Users/hannahkamen/Downloads/unskilled_entrance_college_only.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac292be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
